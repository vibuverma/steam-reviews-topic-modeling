
# Topic Identification for Steam Reviews

Implementing contextual topic identification model using LDA probabilistic topic assignment and pre-trained sentence embeddings from BERT/RoBERTa.
The dataset contains game reviews from steam platform.


## Documentation

[Documentation](https://linktodocumentation)

  + LDA stands for Latent Dirichlet Allocation. It is considered a Bayesian version of pLSA. In particular, it uses priors from Dirichlet distributions for both the document-topic and word-topic distributions, lending itself to better generalization. It is a particularly popular method for fitting a topic model.

    The main assumption that LDA makes is that each document is generated by a statistical generative process i.e, each document is a mixture of topics, and each topic is a mixture of words. This algorithm exactly finding the weight of connections between documents and topics and between topics and words.

  + Sentence Transformers: This framework provides an easy method to compute dense vector representations for sentences, paragraphs, and images. The models are based on transformer networks like BERT / RoBERTa / XLM-RoBERTa etc. and achieve state-of-the-art performance in various task. Text is embedding in vector space such that similar text is close and can efficiently be found using cosine similarity.
## Data

The dataset used: [Steam review dataset](https://www.kaggle.com/luthfim/steam-reviews-dataset).
This data contain reviews from Steam's best selling games as February 2019.

  
## Acknowledgements

 - [Sentence Transformers](https://github.com/UKPLab/sentence-transformers)
 - [Gensim](https://github.com/RaRe-Technologies/gensim)

  
